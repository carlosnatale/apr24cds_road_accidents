{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c107cfc-1949-40b0-bf00-78bc975414f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 447670 entries, 0 to 447669\n",
      "Data columns (total 39 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   AccID                       447670 non-null  object \n",
      " 1   day                         447670 non-null  object \n",
      " 2   month                       447670 non-null  object \n",
      " 3   year                        447670 non-null  object \n",
      " 4   time                        447670 non-null  object \n",
      " 5   lum                         447670 non-null  object \n",
      " 6   atm_condition               447670 non-null  object \n",
      " 7   collision_type              447670 non-null  object \n",
      " 8   lat                         447670 non-null  float64\n",
      " 9   long                        447670 non-null  float64\n",
      " 10  route_category              447670 non-null  object \n",
      " 11  traffic_regime              447670 non-null  object \n",
      " 12  total_number_lanes          447670 non-null  object \n",
      " 13  reserved_lane_code          447670 non-null  object \n",
      " 14  longitudinal_profile        447670 non-null  object \n",
      " 15  upstream_terminal_number    447670 non-null  float64\n",
      " 16  distance_upstream_terminal  447670 non-null  float64\n",
      " 17  plan                        447670 non-null  object \n",
      " 18  surface_condition           447670 non-null  object \n",
      " 19  infra                       447670 non-null  object \n",
      " 20  accident_situation          447670 non-null  object \n",
      " 21  maximum_speed               447670 non-null  object \n",
      " 22  vehicleID                   447670 non-null  object \n",
      " 23  num_veh                     447670 non-null  object \n",
      " 24  traffic_direction           447670 non-null  object \n",
      " 25  vehicle_category            447670 non-null  object \n",
      " 26  fixed_obstacle              447670 non-null  object \n",
      " 27  mobile_obstacle             447670 non-null  object \n",
      " 28  initial_impact_point        447670 non-null  object \n",
      " 29  manv                        447670 non-null  object \n",
      " 30  motor                       447670 non-null  object \n",
      " 31  seat                        447670 non-null  object \n",
      " 32  user_category               447670 non-null  object \n",
      " 33  gravity                     447670 non-null  object \n",
      " 34  gender                      447670 non-null  object \n",
      " 35  birth_year                  447670 non-null  float64\n",
      " 36  reason_travel               447670 non-null  object \n",
      " 37  safety_equipment1           447670 non-null  object \n",
      " 38  age                         447670 non-null  float64\n",
      "dtypes: float64(6), object(33)\n",
      "memory usage: 133.2+ MB\n",
      "Shape of X_train: (358136, 211)\n",
      "Shape of X_test: (89534, 211)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppress specific future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Import the clean data\n",
    "data = pd.read_pickle('source\\data.pkl')\n",
    "\n",
    "data.info()\n",
    "\n",
    "# Copy of the original dataset for feature engineering and preprocessing\n",
    "data_processed = data.copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data_processed = data_processed.drop(['AccID', 'birth_year', 'vehicleID', 'num_veh'], axis=1)\n",
    "\n",
    "# Convert 'day', 'month', and 'time' to integers\n",
    "data_processed['day'] = data_processed['day'].astype(int)\n",
    "data_processed['month'] = data_processed['month'].astype(int)\n",
    "data_processed['time'] = data_processed['time'].astype(int)\n",
    "\n",
    "# Cyclical encoding for temporal features\n",
    "data_processed['day_sin'] = np.sin(2 * np.pi * data_processed['day'] / 31)  \n",
    "data_processed['day_cos'] = np.cos(2 * np.pi * data_processed['day'] / 31)\n",
    "\n",
    "data_processed['month_sin'] = np.sin(2 * np.pi * data_processed['month'] / 12)\n",
    "data_processed['month_cos'] = np.cos(2 * np.pi * data_processed['month'] / 12)\n",
    "\n",
    "data_processed['time_sin'] = np.sin(2 * np.pi * data_processed['time'] / 86340000) \n",
    "data_processed['time_cos'] = np.cos(2 * np.pi * data_processed['time'] / 86340000)\n",
    "\n",
    "data_processed.drop(columns=['day','month','time'],inplace=True)\n",
    "\n",
    "# Selecting features and target variable\n",
    "features_dummy = ['year', 'lum', 'atm_condition', 'collision_type',\n",
    "       'route_category', 'traffic_regime', 'total_number_lanes',\n",
    "       'reserved_lane_code', 'longitudinal_profile', 'plan',\n",
    "       'surface_condition', 'infra', 'accident_situation',\n",
    "       'traffic_direction', 'vehicle_category', 'fixed_obstacle',\n",
    "       'mobile_obstacle', 'initial_impact_point', 'manv', 'motor', 'seat',\n",
    "       'user_category', 'gender', 'reason_travel',\n",
    "       'safety_equipment1']\n",
    "\n",
    "# These features will be standardized\n",
    "features_scaler = ['lat', 'long', 'upstream_terminal_number', 'distance_upstream_terminal', 'maximum_speed', 'age']\n",
    "\n",
    "# These features are between -1 and 1 and do not need any standardazations. \n",
    "features_temporal = ['day_sin', 'day_cos', 'month_sin', 'month_cos', 'time_sin', 'time_cos']\n",
    "target = 'gravity'\n",
    "\n",
    "X = data_processed.drop(columns=[target])\n",
    "y = data_processed[target]\n",
    "y = y.astype(int)\n",
    "\n",
    "X = pd.get_dummies(X, columns=features_dummy, drop_first=True)\n",
    "\n",
    "# stratify will split the dataset according to the distribution of the classes to compensate for imbalanced datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardization: Fit only on the training data, then apply to both train and test\n",
    "scaler = StandardScaler()\n",
    "X_train[features_scaler] = scaler.fit_transform(X_train[features_scaler])\n",
    "X_test[features_scaler] = scaler.transform(X_test[features_scaler])\n",
    "\n",
    "# Check the dimensions\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf330c-4e55-4eb1-914f-947679236b1c",
   "metadata": {},
   "source": [
    "Apply ML v1 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcbbb0b-7b29-4d33-9479-f08030da600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6367413496548797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.80      0.74     37537\n",
      "           2       0.29      0.03      0.06      2256\n",
      "           3       0.50      0.36      0.42     13565\n",
      "           4       0.62      0.61      0.61     36176\n",
      "\n",
      "    accuracy                           0.64     89534\n",
      "   macro avg       0.52      0.45      0.46     89534\n",
      "weighted avg       0.62      0.64      0.62     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4f7e4-5c69-4993-a5f9-f38cc8c5e14a",
   "metadata": {},
   "source": [
    "Apply ML v2 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ad7b5-a653-41ae-97bf-eb3bb3566238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Grid search to optimize for f1_weighted \n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'base_estimator__max_depth': [1, 2]  \n",
    "}\n",
    "\n",
    "# Initialize a base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1, class_weight='balanced')\n",
    "\n",
    "# Initialize the AdaBoost classifier with the base estimator\n",
    "ada_clf = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation, optimizing for weighted F1 score\n",
    "grid_search = GridSearchCV(estimator=ada_clf, param_grid=param_grid, scoring='f1_weighted', cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params_f1 = grid_search.best_params_\n",
    "best_score_f1 = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params_f1}\")\n",
    "print(f\"Best F1 score: {best_score_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeace6ca-745d-4642-b69d-f6cec69d4fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for AdaBoost with best parameters:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.82      0.76     37537\n",
      "           2       0.30      0.12      0.17      2256\n",
      "           3       0.51      0.39      0.44     13565\n",
      "           4       0.64      0.62      0.63     36176\n",
      "\n",
      "    accuracy                           0.66     89534\n",
      "   macro avg       0.54      0.49      0.50     89534\n",
      "weighted avg       0.64      0.66      0.65     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Initialize the base estimator with max_depth=2\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Initialize AdaBoostClassifier with the best hyperparameters\n",
    "ada_clf_best = AdaBoostClassifier(\n",
    "    base_estimator=base_estimator, \n",
    "    n_estimators=200, \n",
    "    learning_rate=1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the classifier on the training data\n",
    "ada_clf_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best = ada_clf_best.predict(X_test)\n",
    "\n",
    "# Alternatively, you can use cross-validation to get predictions\n",
    "# y_pred_best = cross_val_predict(ada_clf_best, X_train, y_train, cv=5)\n",
    "\n",
    "# Generate and display the classification report\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "print(\"Classification Report for AdaBoost with best parameters:\")\n",
    "print(class_report_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549b012-1858-4dc0-9844-dce26c7d2295",
   "metadata": {},
   "source": [
    "Apply ML OVER SAMPLING - v3 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4aa004-02aa-42be-8f47-40de71c47595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.75      0.73     37537\n",
      "           2       0.19      0.16      0.17      2256\n",
      "           3       0.43      0.44      0.44     13565\n",
      "           4       0.62      0.58      0.60     36176\n",
      "\n",
      "    accuracy                           0.62     89534\n",
      "   macro avg       0.49      0.48      0.48     89534\n",
      "weighted avg       0.62      0.62      0.62     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to oversample the minority classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the AdaBoostClassifier with the best hyperparameters on the resampled dataset\n",
    "ada_clf_best = AdaBoostClassifier(n_estimators=200, learning_rate=1, random_state=42)\n",
    "ada_clf_best.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_resampled = ada_clf_best.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report_resampled = classification_report(y_test, y_pred_resampled)\n",
    "print(class_report_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de672d-3d4f-4471-8479-9737066b4f0b",
   "metadata": {},
   "source": [
    "Apply ML UNDER SAMPLING - v4 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56af2395-f9c3-43f6-acdc-957a4dcae4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.75      0.73     37537\n",
      "           2       0.12      0.61      0.20      2256\n",
      "           3       0.38      0.40      0.39     13565\n",
      "           4       0.67      0.44      0.53     36176\n",
      "\n",
      "    accuracy                           0.57     89534\n",
      "   macro avg       0.47      0.55      0.46     89534\n",
      "weighted avg       0.63      0.57      0.59     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply RandomUnderSampler to reduce the number of samples in the majority classes\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the AdaBoostClassifier with the best hyperparameters on the resampled dataset\n",
    "ada_clf_best = AdaBoostClassifier(n_estimators=200, learning_rate=1, random_state=42)\n",
    "ada_clf_best.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_resampled = ada_clf_best.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report_resampled = classification_report(y_test, y_pred_resampled)\n",
    "print(class_report_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fc3e4-2d81-471c-b37c-5059edf00809",
   "metadata": {},
   "source": [
    "Apply ML CLASS WEIGHT - v5 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb87ad3-5f99-43de-a4ed-81ce261d7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76     37537\n",
      "           2       0.13      0.62      0.22      2256\n",
      "           3       0.38      0.42      0.40     13565\n",
      "           4       0.71      0.46      0.55     36176\n",
      "\n",
      "    accuracy                           0.59     89534\n",
      "   macro avg       0.49      0.57      0.48     89534\n",
      "weighted avg       0.65      0.59      0.61     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Define a base classifier with class weights\n",
    "base_clf = DecisionTreeClassifier(class_weight='balanced', max_depth=2)\n",
    "\n",
    "# Use this base classifier in AdaBoost\n",
    "ada_clf_weighted = AdaBoostClassifier(base_estimator=base_clf, n_estimators=200, learning_rate=1, random_state=42)\n",
    "\n",
    "# Train on the original dataset\n",
    "ada_clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_weighted = ada_clf_weighted.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "class_report_weighted = classification_report(y_test, y_pred_weighted)\n",
    "print(class_report_weighted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29593e-5c00-49c7-8a65-64b91c268e04",
   "metadata": {},
   "source": [
    "Apply ML BINARY - Fatal vs Non-fatal v6 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43efdd45-fdf3-4727-a5f9-513e925905b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     87279\n",
      "           1       0.38      0.04      0.08      2255\n",
      "\n",
      "    accuracy                           0.97     89534\n",
      "   macro avg       0.68      0.52      0.53     89534\n",
      "weighted avg       0.96      0.97      0.96     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping classes into two: Fatal (class 2) and Non-fatal (classes 1, 3, and 4)\n",
    "\n",
    "# Create a new target variable with two classes\n",
    "y_grouped = y.copy()\n",
    "y_grouped = y_grouped.replace({1: 0, 3: 0, 4: 0, 2: 1})  # 0 for non-fatal, 1 for fatal\n",
    "\n",
    "# Split the dataset again with the new target\n",
    "X_train_grouped, X_test_grouped, y_train_grouped, y_test_grouped = train_test_split(X, y_grouped, test_size=0.2, stratify=y_grouped, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost classifier with the best hyperparameters from previous tests\n",
    "ada_clf_grouped = AdaBoostClassifier(n_estimators=200, learning_rate=1, random_state=42)\n",
    "\n",
    "# Train the classifier on the new grouped target\n",
    "ada_clf_grouped.fit(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_grouped = ada_clf_grouped.predict(X_test_grouped)\n",
    "\n",
    "# Generate the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "class_report_grouped = classification_report(y_test_grouped, y_pred_grouped)\n",
    "\n",
    "print(class_report_grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429d460-6f28-4a00-b0ae-04cec0c1b275",
   "metadata": {},
   "source": [
    "Apply ML BINARY - Fatal vs Non-fatal - UNDER SAMPLING v7 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696772d0-e26e-46fa-8c1f-f5c6fbbd13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89     87279\n",
      "           1       0.09      0.80      0.17      2255\n",
      "\n",
      "    accuracy                           0.80     89534\n",
      "   macro avg       0.54      0.80      0.53     89534\n",
      "weighted avg       0.97      0.80      0.87     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply RandomUnderSampler to reduce the number of samples in the majority class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Train the classifier on the undersampled data\n",
    "ada_clf_grouped.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_resampled = ada_clf_grouped.predict(X_test_grouped)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(classification_report(y_test_grouped, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a685e-7cb3-4aea-9374-9c57d7a80428",
   "metadata": {},
   "source": [
    "Apply ML BINARY - Fatal vs Non-fatal - OVER SAMPLING v8 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc478cb-272f-458d-b803-d6416462b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     87279\n",
      "           1       0.18      0.13      0.15      2255\n",
      "\n",
      "    accuracy                           0.96     89534\n",
      "   macro avg       0.58      0.56      0.57     89534\n",
      "weighted avg       0.96      0.96      0.96     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Train the classifier on the resampled data\n",
    "ada_clf_grouped.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_pred_resampled = ada_clf_grouped.predict(X_test_grouped)\n",
    "print(classification_report(y_test_grouped, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a654745-a8f4-48fd-818b-ea0a7edf62ff",
   "metadata": {},
   "source": [
    "Apply ML BINARY - Fatal vs Non-fatal - CLASS WEIGHT v9 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee4c4236-b05f-4e7f-aedb-cf91da0b3954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     87279\n",
      "           1       0.16      0.16      0.16      2255\n",
      "\n",
      "    accuracy                           0.96     89534\n",
      "   macro avg       0.57      0.57      0.57     89534\n",
      "weighted avg       0.96      0.96      0.96     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the base classifier with class weights\n",
    "base_clf = DecisionTreeClassifier(class_weight={0: 1, 1: 10})\n",
    "\n",
    "# Initialize AdaBoost with the base classifier\n",
    "ada_clf_weighted = AdaBoostClassifier(base_estimator=base_clf, n_estimators=200, learning_rate=1, random_state=42)\n",
    "\n",
    "# Train the classifier with class weights\n",
    "ada_clf_weighted.fit(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_pred_weighted = ada_clf_weighted.predict(X_test_grouped)\n",
    "print(classification_report(y_test_grouped, y_pred_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4d8ec-5c4c-45ff-88a9-1126449fe672",
   "metadata": {},
   "source": [
    "Apply ML BINARY - Slightly Injured, 1 for Severely Injured v10 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8434148e-e9e8-4eba-b9eb-8bf73f282fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     73714\n",
      "           1       0.64      0.38      0.48     15820\n",
      "\n",
      "    accuracy                           0.85     89534\n",
      "   macro avg       0.76      0.67      0.70     89534\n",
      "weighted avg       0.83      0.85      0.84     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping classes into two: Severely Injured (classes 2 and 3) and Slightly Injured (classes 1 and 4)\n",
    "\n",
    "# Create a new target variable with two classes\n",
    "y_grouped_2 = y.copy()\n",
    "y_grouped_2 = y_grouped_2.replace({1: 0, 4: 0, 2: 1, 3: 1})  # 0 for Slightly Injured, 1 for Severely Injured\n",
    "\n",
    "# Split the dataset again with the new target\n",
    "X_train_grouped_2, X_test_grouped_2, y_train_grouped_2, y_test_grouped_2 = train_test_split(\n",
    "    X, y_grouped_2, test_size=0.2, stratify=y_grouped_2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize AdaBoost classifier with the best hyperparameters from previous tests\n",
    "ada_clf_grouped_2 = AdaBoostClassifier(n_estimators=200, learning_rate=1, random_state=42)\n",
    "\n",
    "# Train the classifier on the new grouped target\n",
    "ada_clf_grouped_2.fit(X_train_grouped_2, y_train_grouped_2)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_grouped_2 = ada_clf_grouped_2.predict(X_test_grouped_2)\n",
    "\n",
    "# Generate the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "class_report_grouped_2 = classification_report(y_test_grouped_2, y_pred_grouped_2)\n",
    "\n",
    "print(class_report_grouped_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "405ee04e-7a71-4da1-9935-04a96459b4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85     73714\n",
      "           1       0.43      0.80      0.56     15820\n",
      "\n",
      "    accuracy                           0.78     89534\n",
      "   macro avg       0.69      0.78      0.70     89534\n",
      "weighted avg       0.85      0.78      0.80     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Group classes into Slightly Injured (0) and Severely Injured (1)\n",
    "y_grouped = y.copy()\n",
    "y_grouped = y_grouped.replace({1: 0, 4: 0, 2: 1, 3: 1})\n",
    "\n",
    "# Split the dataset\n",
    "X_train_grouped, X_test_grouped, y_train_grouped, y_test_grouped = train_test_split(\n",
    "    X, y_grouped, test_size=0.2, stratify=y_grouped, random_state=42\n",
    ")\n",
    "\n",
    "# Apply RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_undersampled, y_train_undersampled = rus.fit_resample(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Train the AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=200, learning_rate=1, random_state=42)\n",
    "ada_clf.fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_pred_undersampled = ada_clf.predict(X_test_grouped)\n",
    "class_report_undersampled = classification_report(y_test_grouped, y_pred_undersampled)\n",
    "print(\"Undersampling Classification Report:\\n\", class_report_undersampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18adfa2-dac8-4311-a104-09741e0df35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling with SMOTE Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     73714\n",
      "           1       0.54      0.44      0.49     15820\n",
      "\n",
      "    accuracy                           0.84     89534\n",
      "   macro avg       0.71      0.68      0.69     89534\n",
      "weighted avg       0.82      0.84      0.83     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Group classes into Slightly Injured (0) and Severely Injured (1)\n",
    "y_grouped = y.copy()\n",
    "y_grouped = y_grouped.replace({1: 0, 4: 0, 2: 1, 3: 1})\n",
    "\n",
    "# Split the dataset\n",
    "X_train_grouped, X_test_grouped, y_train_grouped, y_test_grouped = train_test_split(\n",
    "    X, y_grouped, test_size=0.2, stratify=y_grouped, random_state=42\n",
    ")\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Train the AdaBoost classifier\n",
    "ada_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_pred_oversampled = ada_clf.predict(X_test_grouped)\n",
    "class_report_oversampled = classification_report(y_test_grouped, y_pred_oversampled)\n",
    "print(\"Oversampling with SMOTE Classification Report:\\n\", class_report_oversampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e94914f-1ad9-4c08-a71d-7b15b33c82a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     73714\n",
      "           1       0.44      0.46      0.45     15820\n",
      "\n",
      "    accuracy                           0.80     89534\n",
      "   macro avg       0.66      0.67      0.66     89534\n",
      "weighted avg       0.80      0.80      0.80     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Group classes into Slightly Injured (0) and Severely Injured (1)\n",
    "y_grouped = y.copy()\n",
    "y_grouped = y_grouped.replace({1: 0, 4: 0, 2: 1, 3: 1})\n",
    "\n",
    "# Split the dataset\n",
    "X_train_grouped, X_test_grouped, y_train_grouped, y_test_grouped = train_test_split(\n",
    "    X, y_grouped, test_size=0.2, stratify=y_grouped, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the AdaBoost classifier with class weights\n",
    "base_clf = DecisionTreeClassifier(class_weight={0: 1, 1: 10})  # Adjust class weights\n",
    "ada_clf_weighted = AdaBoostClassifier(base_estimator=base_clf, n_estimators=200, learning_rate=1, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "ada_clf_weighted.fit(X_train_grouped, y_train_grouped)\n",
    "\n",
    "# Predict and generate classification report\n",
    "y_pred_weighted = ada_clf_weighted.predict(X_test_grouped)\n",
    "class_report_weighted = classification_report(y_test_grouped, y_pred_weighted)\n",
    "print(\"Class Weights Classification Report:\\n\", class_report_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82751bc4-61ca-4310-b857-4b2e2d92b387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
