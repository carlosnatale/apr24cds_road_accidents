{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c107cfc-1949-40b0-bf00-78bc975414f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 447670 entries, 0 to 447669\n",
      "Data columns (total 39 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   AccID                       447670 non-null  object \n",
      " 1   day                         447670 non-null  object \n",
      " 2   month                       447670 non-null  object \n",
      " 3   year                        447670 non-null  object \n",
      " 4   time                        447670 non-null  object \n",
      " 5   lum                         447670 non-null  object \n",
      " 6   atm_condition               447670 non-null  object \n",
      " 7   collision_type              447670 non-null  object \n",
      " 8   lat                         447670 non-null  float64\n",
      " 9   long                        447670 non-null  float64\n",
      " 10  route_category              447670 non-null  object \n",
      " 11  traffic_regime              447670 non-null  object \n",
      " 12  total_number_lanes          447670 non-null  object \n",
      " 13  reserved_lane_code          447670 non-null  object \n",
      " 14  longitudinal_profile        447670 non-null  object \n",
      " 15  upstream_terminal_number    447670 non-null  float64\n",
      " 16  distance_upstream_terminal  447670 non-null  float64\n",
      " 17  plan                        447670 non-null  object \n",
      " 18  surface_condition           447670 non-null  object \n",
      " 19  infra                       447670 non-null  object \n",
      " 20  accident_situation          447670 non-null  object \n",
      " 21  maximum_speed               447670 non-null  object \n",
      " 22  vehicleID                   447670 non-null  object \n",
      " 23  num_veh                     447670 non-null  object \n",
      " 24  traffic_direction           447670 non-null  object \n",
      " 25  vehicle_category            447670 non-null  object \n",
      " 26  fixed_obstacle              447670 non-null  object \n",
      " 27  mobile_obstacle             447670 non-null  object \n",
      " 28  initial_impact_point        447670 non-null  object \n",
      " 29  manv                        447670 non-null  object \n",
      " 30  motor                       447670 non-null  object \n",
      " 31  seat                        447670 non-null  object \n",
      " 32  user_category               447670 non-null  object \n",
      " 33  gravity                     447670 non-null  object \n",
      " 34  gender                      447670 non-null  object \n",
      " 35  birth_year                  447670 non-null  float64\n",
      " 36  reason_travel               447670 non-null  object \n",
      " 37  safety_equipment1           447670 non-null  object \n",
      " 38  age                         447670 non-null  float64\n",
      "dtypes: float64(6), object(33)\n",
      "memory usage: 133.2+ MB\n",
      "Shape of X_train: (358136, 211)\n",
      "Shape of X_test: (89534, 211)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppress specific future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Import the clean data\n",
    "data = pd.read_pickle('source\\data.pkl')\n",
    "\n",
    "data.info()\n",
    "\n",
    "# Copy of the original dataset for feature engineering and preprocessing\n",
    "data_processed = data.copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data_processed = data_processed.drop(['AccID', 'birth_year', 'vehicleID', 'num_veh'], axis=1)\n",
    "\n",
    "# Convert 'day', 'month', and 'time' to integers\n",
    "data_processed['day'] = data_processed['day'].astype(int)\n",
    "data_processed['month'] = data_processed['month'].astype(int)\n",
    "data_processed['time'] = data_processed['time'].astype(int)\n",
    "\n",
    "# Cyclical encoding for temporal features\n",
    "data_processed['day_sin'] = np.sin(2 * np.pi * data_processed['day'] / 31)  \n",
    "data_processed['day_cos'] = np.cos(2 * np.pi * data_processed['day'] / 31)\n",
    "\n",
    "data_processed['month_sin'] = np.sin(2 * np.pi * data_processed['month'] / 12)\n",
    "data_processed['month_cos'] = np.cos(2 * np.pi * data_processed['month'] / 12)\n",
    "\n",
    "data_processed['time_sin'] = np.sin(2 * np.pi * data_processed['time'] / 86340000) \n",
    "data_processed['time_cos'] = np.cos(2 * np.pi * data_processed['time'] / 86340000)\n",
    "\n",
    "data_processed.drop(columns=['day','month','time'],inplace=True)\n",
    "\n",
    "# Selecting features and target variable\n",
    "features_dummy = ['year', 'lum', 'atm_condition', 'collision_type',\n",
    "       'route_category', 'traffic_regime', 'total_number_lanes',\n",
    "       'reserved_lane_code', 'longitudinal_profile', 'plan',\n",
    "       'surface_condition', 'infra', 'accident_situation',\n",
    "       'traffic_direction', 'vehicle_category', 'fixed_obstacle',\n",
    "       'mobile_obstacle', 'initial_impact_point', 'manv', 'motor', 'seat',\n",
    "       'user_category', 'gender', 'reason_travel',\n",
    "       'safety_equipment1']\n",
    "\n",
    "# These features will be standardized\n",
    "features_scaler = ['lat', 'long', 'upstream_terminal_number', 'distance_upstream_terminal', 'maximum_speed', 'age']\n",
    "\n",
    "# These features are between -1 and 1 and do not need any standardazations. \n",
    "features_temporal = ['day_sin', 'day_cos', 'month_sin', 'month_cos', 'time_sin', 'time_cos']\n",
    "target = 'gravity'\n",
    "\n",
    "X = data_processed.drop(columns=[target])\n",
    "y = data_processed[target]\n",
    "y = y.astype(int)\n",
    "\n",
    "X = pd.get_dummies(X, columns=features_dummy, drop_first=True)\n",
    "\n",
    "# stratify will split the dataset according to the distribution of the classes to compensate for imbalanced datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardization: Fit only on the training data, then apply to both train and test\n",
    "scaler = StandardScaler()\n",
    "X_train[features_scaler] = scaler.fit_transform(X_train[features_scaler])\n",
    "X_test[features_scaler] = scaler.transform(X_test[features_scaler])\n",
    "\n",
    "# Check the dimensions\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf330c-4e55-4eb1-914f-947679236b1c",
   "metadata": {},
   "source": [
    "Apply ML v1 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4978fa-a82f-401a-acbd-dc010bfb6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Fatal       0.98      1.00      0.99     87278\n",
      "       Fatal       0.49      0.06      0.10      2256\n",
      "\n",
      "    accuracy                           0.97     89534\n",
      "   macro avg       0.73      0.53      0.55     89534\n",
      "weighted avg       0.96      0.97      0.96     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the XGBoost model on the preprocessed data, assuming the initial preprocessing code was already executed\n",
    "\n",
    "# Import XGBoost and metrics packages for classification\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Modify the target variable 'gravity' to have two classes: 1 (Fatal) and 0 (Non-Fatal)\n",
    "# 2 -> Fatal, 1/3/4 -> Non-Fatal\n",
    "y_train = y_train.replace({2: 1, 1: 0, 3: 0, 4: 0})\n",
    "y_test = y_test.replace({2: 1, 1: 0, 3: 0, 4: 0})\n",
    "\n",
    "# Initialize and train the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "classification_report_output = classification_report(y_test, y_pred, target_names=[\"Non-Fatal\", \"Fatal\"])\n",
    "\n",
    "print(classification_report_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a314942-9fd7-44db-a2cb-1ec7734a92e2",
   "metadata": {},
   "source": [
    "Apply ML v2 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7bcfb5-cbe1-44f5-ae1f-3599eb238e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters found:  {'subsample': 0.7, 'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.3, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "Best score found:  0.9651621121453178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Fatal       0.98      1.00      0.99     87278\n",
      "       Fatal       0.46      0.07      0.12      2256\n",
      "\n",
      "    accuracy                           0.97     89534\n",
      "   macro avg       0.72      0.53      0.56     89534\n",
      "weighted avg       0.96      0.97      0.97     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  \n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the search on the training set\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the tuned model on the test set\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Fatal\", \"Fatal\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd2bb7-3a7c-4f9a-b65e-7cf4faaa8ea7",
   "metadata": {},
   "source": [
    "Apply ML v3-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9752c29-3ff2-4fc0-9bbf-02541c77ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=50. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [400],\n",
    "    'max_depth': [4],\n",
    "    'learning_rate': [0.3],\n",
    "    'subsample': [0.7],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'gamma': [0.1]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  \n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the search on the training set\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the tuned model on the test set\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Fatal\", \"Fatal\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5034b2-ed3e-4148-8405-e896362899f1",
   "metadata": {},
   "source": [
    "Apply ML v4--------> SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0801ab4-652d-462e-a3cb-5d4c668068d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize SMOTE with a random state for reproducibility\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters found in previous tuning\n",
    "xgb_model_smote = xgb.XGBClassifier(\n",
    "    n_estimators=400, \n",
    "    max_depth=4, \n",
    "    learning_rate=0.3, \n",
    "    subsample=0.7, \n",
    "    colsample_bytree=0.8, \n",
    "    gamma=0.1, \n",
    "    random_state=42, \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_smote = xgb_model_smote.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_output_smote = classification_report(y_test, y_pred_smote, target_names=[\"Non-Fatal\", \"Fatal\"])\n",
    "print(classification_report_output_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98586e4c-9088-4bb6-95ab-f0eeed6dfd03",
   "metadata": {},
   "source": [
    "Apply ML v5-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d254069-ed81-48a1-a5be-803769dc7ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ede3807-0948-4f9b-a68c-3ebeb9e46875",
   "metadata": {},
   "source": [
    "Apply ML v6-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834de2f-516b-4d09-a1d0-46b7c2d1e442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb60ac05-3453-4644-b7e4-d5c2133a4041",
   "metadata": {},
   "source": [
    "Apply ML v7-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c8bce-49e8-45fe-b972-c60fd79ebffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9b46c35-7204-4789-8347-de28cc7843a1",
   "metadata": {},
   "source": [
    "Apply ML v8-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08fdfe-9684-4561-a07e-41c6fb65d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b15a88d-75b2-4bfb-9b80-36c74ed386ae",
   "metadata": {},
   "source": [
    "Apply ML v10-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24412a33-587c-46f4-80dd-2c28e102198c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c1fd282-e36b-458f-825d-4f101f0e3dee",
   "metadata": {},
   "source": [
    "Apply ML v11-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd736bef-2e1e-42d5-91c7-5f5abb7a2edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
