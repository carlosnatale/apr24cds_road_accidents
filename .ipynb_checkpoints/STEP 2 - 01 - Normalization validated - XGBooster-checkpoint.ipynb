{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cc1bdc-c064-433a-a16f-b2cc2106f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0d7786-afdb-4053-bf8d-3597a26bfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf07a27d-de3e-4826-bf68-4152043359a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clean data\n",
    "data = pd.read_csv('source/data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2b88f9-4be5-49b0-b78b-9bc4326e3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the original dataset for feature engineering and preprocessing\n",
    "data_processed = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "834dad4e-eb67-4eeb-a34b-a36413984127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data_processed = data_processed.drop(['AccID', 'birth_year', 'vehicleID', 'num_veh'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97fb1efa-32e9-4a21-b996-cbe3eee16622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'time', 'day', 'month', and 'year' to float type\n",
    "data_processed['time'] = data_processed['time'].astype('float64')\n",
    "data_processed['day'] = data_processed['day'].astype('float64')\n",
    "data_processed['month'] = data_processed['month'].astype('float64')\n",
    "data_processed['year'] = data_processed['year'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e10343-9e2f-47e6-9224-c14146f4854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features and target variable\n",
    "features = ['lum', 'atm_condition', 'collision_type', 'route_category', 'traffic_regime', 'reserved_lane_code', \n",
    "            'longitudinal_profile', 'upstream_terminal_number', 'plan', 'surface_condition', 'infra', 'accident_situation', \n",
    "            'traffic_direction', 'vehicle_category', 'fixed_obstacle', 'mobile_obstacle', 'initial_impact_point', 'manv', \n",
    "            'motor', 'seat', 'user_category', 'gender', 'reason_travel', 'safety_equipment1', 'maximum_speed', 'age', \n",
    "            'lat', 'long', 'distance_upstream_terminal', 'total_number_lanes', 'day', 'time', 'month', 'year']\n",
    "target = 'gravity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af3da25-aa13-43c8-86a2-5d48b1a66499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling categorical features with One Hot Encoding\n",
    "X = pd.get_dummies(data_processed[features], drop_first=True)\n",
    "y = data_processed[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c3c5c5-02fc-40a9-91ff-7c718c28199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65525ce9-7a5c-42ea-a8ba-ea2d8867e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization: Fit only on the training data, then apply to both train and test\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = X.select_dtypes(include=['float64']).columns\n",
    "\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0b5007-ad17-46d3-842c-2272939d9ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (358136, 34)\n",
      "Shape of X_test: (89534, 34)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18642a82-2b9e-4154-a5ec-37ab14e26c7a",
   "metadata": {},
   "source": [
    "Apply ML model v1---->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5411505-2e56-495e-948c-b763116a2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd213736-4d19-4998-82a3-8a9eb247fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X = pd.get_dummies(data_processed[features], drop_first=True)\n",
    "y = data_processed[target] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c2ab55-edc3-482e-b86e-26995fea39fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to handle class imbalance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3249605-2dd7-4d28-8281-1916ffd4ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique classes in the resampled data to ensure all are accounted for\n",
    "unique_classes = np.unique(y_res)\n",
    "print(\"Unique classes after SMOTE:\", unique_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dcb4e-c3c5-4523-9a2b-6e2cd613ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up class weights to handle all classes present\n",
    "class_weights = {0: 1, 1: 20, 2: 1, 3: 1}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca08a95a-79d8-431d-bc8f-5738a6f9ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the sample weights for each resampled data point\n",
    "sample_weights = [class_weights[class_label] for class_label in y_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50178404-605f-41eb-b687-03c7df77af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the XGBoost model with class weights\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', random_state=42, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_res, y_res, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e84a2-fc3c-49d4-8e59-4557ce1a90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set and evaluate\n",
    "y_probs = xgb_model.predict_proba(X_test)\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9403ab1-5c07-4387-a3e1-e997515793d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial classification report without threshold adjustment\n",
    "print(\"XGBoost Classification Report (Without Threshold Adjustment):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1605f-a966-4163-81de-71af9334e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Tuning \n",
    "fatal_probs = y_probs[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040edb51-4b36-480f-9772-cf17bc4e20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use precision-recall curve to find the best threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test == 1, fatal_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd638a5-999d-4529-bdb1-25f56f6e496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best threshold based on the highest F1 score\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c240d-64d1-4bb8-b8a1-0e7586350226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the best threshold for fatal accident prediction\n",
    "y_pred_threshold = (fatal_probs >= best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb0ccf-b230-49d3-b4de-7a41a71d5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report after threshold adjustment for fatalities\n",
    "print(f\"Best Threshold: {best_threshold}\")\n",
    "print(\"Classification report after threshold tuning for fatalities:\")\n",
    "print(classification_report(y_test == 1, y_pred_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78913ea-963b-43ef-95b9-a62dcf33678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apply ML model v2---->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e10ea9-486e-4899-9551-455d4a9690e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the XGBoost model (use your prepared dataset)\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', random_state=42, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_res, y_res)\n",
    "\n",
    "# Get feature importance from the model\n",
    "feature_importance = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(20, 12))\n",
    "xgb.plot_importance(xgb_model, importance_type='weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c1ece-14fd-45f7-b4b2-8cd45992ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', random_state=42,\n",
    "                              eval_metric='mlogloss',\n",
    "                              reg_lambda=1,  # L2 regularization (increase to reduce weight variance)\n",
    "                              reg_alpha=0.5)  # L1 regularization (increase to drive less important features towards zero)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_res, y_res)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3103dc-e805-4710-afcf-c146fe637b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apply ML model v3---->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f3c50-f358-4c28-b70d-dd718f7483e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of trees\n",
    "    'max_depth': [4, 6, 8],           # Maximum depth of each tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1], # Learning rate\n",
    "    'min_child_weight': [1, 3, 5],    # Minimum child weight\n",
    "    'subsample': [0.6, 0.8, 1.0],     # Subsample ratio of training instances\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0], # Subsample ratio of features\n",
    "    'gamma': [0, 0.1, 0.2],           # Minimum loss reduction for a split\n",
    "    'scale_pos_weight': [10, 20, 30]   # Balance class imbalance for fatalities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba2ca0-7cab-4c42-96af-baf6e37d22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', random_state=42, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821e3d6-a184-43c0-92f2-b5408a67bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV to search for the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='f1_macro', cv=3, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ef340-8f24-4f67-a695-f33ec8237232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with grid search\n",
    "grid_search.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cffd81-9c83-4b78-802a-3aa54d95c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best F1 Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207923f-f76b-4cc8-b71a-0826981ec172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to predict on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1d5b6-70a8-4459-8b38-0c34ce126688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for the best model\n",
    "print(\"Classification Report for Best Model:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d78eb-f20a-4e86-ba0a-f86e090c9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apply ML model v4---->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3c693e-f265-4875-9dee-4c62f31b010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo os modelos\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "\n",
    "# Definindo os hiperparâmetros a serem ajustados para XGBoost\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5f89fd-0fb8-4ecb-8a0b-ffddac2b3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Melhores hiperparâmetros para XGBoost: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Configurando o GridSearchCV para XGBoost\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "print(\"Melhores hiperparâmetros para XGBoost:\", grid_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfd027-a1d3-4ca5-a780-bc42ab989b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apply ML model v5---->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "637a21ef-9361-4fda-8b3b-0a306fe77f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 scores (weighted): [0.6810588  0.68317038 0.68515886]\n",
      "Mean CV F1 score: 0.6831293441537873\n",
      "Test Accuracy: 0.6980\n",
      "Test F1 Score (weighted): 0.6881\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the hyperparameters\n",
    "hyperparameters = {\n",
    "    'colsample_bytree': 0.5,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 9,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Assuming X and y are your feature matrix and target vector\n",
    "# Split data into training and testing sets if not done already\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier with specified hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(**hyperparameters, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=3, scoring=make_scorer(f1_score, average='weighted'))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-validation F1 scores (weighted):\", cv_scores)\n",
    "print(\"Mean CV F1 score:\", cv_scores.mean())\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test F1 Score (weighted): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4213129f-a9a8-4528-a8d2-bcfea4eaae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79     37371\n",
      "           1       0.47      0.08      0.14      2335\n",
      "           2       0.55      0.47      0.51     13737\n",
      "           3       0.68      0.68      0.68     36091\n",
      "\n",
      "    accuracy                           0.70     89534\n",
      "   macro avg       0.61      0.52      0.53     89534\n",
      "weighted avg       0.69      0.70      0.69     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980be65f-d6ba-40f6-9921-c5a6626e1b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
