{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159ef34-0d25-462e-bac0-bf5e5fba22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b68d4-59f5-4f9f-89d7-15f92235fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and process files based on the given conditions\n",
    "def process_files(file_list, column_order, rename_dict, drop_column=None):\n",
    "    dfs = []\n",
    "    for file in file_list:\n",
    "        df = pd.read_csv(file, delimiter=';', on_bad_lines='skip', dtype=str)\n",
    "        if \"Accident_Id\" in df.columns:\n",
    "            df.rename(columns={\"Accident_Id\": \"Num_Acc\"}, inplace=True)\n",
    "        if drop_column and drop_column in df.columns:\n",
    "            df.drop(columns=[drop_column], inplace=True)\n",
    "        df = df.reindex(columns=column_order)\n",
    "        dfs.append(df)\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df.rename(columns=rename_dict, inplace=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8529d4-9fb5-40a1-84a1-704da7aee0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "source_folder = \"source/\"\n",
    "caracteristiques_files = [os.path.join(source_folder, f) for f in os.listdir(source_folder) if f.startswith(\"caracteristiques\")]\n",
    "lieux_files = [os.path.join(source_folder, f) for f in os.listdir(source_folder) if f.startswith(\"lieux\")]\n",
    "usagers_files = [os.path.join(source_folder, f) for f in os.listdir(source_folder) if f.startswith(\"usagers\")]\n",
    "vehicules_files = [os.path.join(source_folder, f) for f in os.listdir(source_folder) if f.startswith(\"vehicules\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907a9d7-90b5-4773-8c70-fb72716f204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column orders and rename dictionaries\n",
    "caracteristiques_columns = [\"Num_Acc\", \"jour\", \"mois\", \"an\", \"hrmn\", \"lum\", \"dep\", \"com\", \"agg\", \"int\", \"atm\", \"col\", \"adr\", \"lat\", \"long\"]\n",
    "caracteristiques_rename = {\"Num_Acc\": \"AccID\", \"jour\": \"day\", \"mois\": \"month\", \"an\": \"year\", \"hrmn\": \"time\", \"lum\": \"lum\", \n",
    "                           \"dep\": \"dep_code\", \"com\": \"com_code\", \"agg\": \"location\", \"int\": \"int\", \"atm\": \"atm_condition\", \n",
    "                           \"col\": \"collision_type\", \"adr\": \"address\", \"lat\": \"lat\", \"long\": \"long\"}\n",
    "\n",
    "lieux_columns = [\"Num_Acc\", \"catr\", \"voie\", \"v1\", \"v2\", \"circ\", \"nbv\", \"vosp\", \"prof\", \"pr\", \"pr1\", \"plan\", \"lartpc\", \n",
    "                 \"larrout\", \"surf\", \"infra\", \"situ\", \"vma\"]\n",
    "lieux_rename = {\"Num_Acc\": \"AccID\", \"catr\": \"route_category\", \"voie\": \"route_number\", \"v1\": \"route_number_index1\", \n",
    "                \"v2\": \"alph_route_index\", \"circ\": \"traffic_regime\", \"nbv\": \"total_number_lanes\", \"vosp\": \"reserved_lane_code\", \n",
    "                \"prof\": \"longitudinal_profile\", \"pr\": \"upstream_terminal_number\", \"pr1\": \"distance_upstream_terminal\", \n",
    "                \"plan\": \"plan\", \"lartpc\": \"width_central_reservation\", \"larrout\": \"width_roadway\", \"surf\": \"surface_condition\", \n",
    "                \"infra\": \"infra\", \"situ\": \"accident_situation\", \"vma\": \"maximum_speed\"}\n",
    "\n",
    "usagers_columns = [\"Num_Acc\", \"id_vehicule\", \"num_veh\", \"place\", \"catu\", \"grav\", \"sexe\", \"an_nais\", \"trajet\", \"secu1\", \n",
    "                   \"secu2\", \"secu3\", \"locp\", \"actp\", \"etatp\"]\n",
    "usagers_rename = {\"Num_Acc\": \"AccID\", \"id_vehicule\": \"vehicleID\", \"num_veh\": \"num_veh\", \"place\": \"seat\", \"catu\": \"user_category\", \n",
    "                  \"grav\": \"gravity\", \"sexe\": \"gender\", \"an_nais\": \"birth_year\", \"trajet\": \"reason_travel\", \"secu1\": \"safety_equipment1\", \n",
    "                  \"secu2\": \"safety_equipment2\", \"secu3\": \"safety_equipment3\", \"locp\": \"pedestrian_location\", \"actp\": \"pedestrian_action\", \n",
    "                  \"etatp\": \"pedestrian_involved\"}\n",
    "\n",
    "vehicules_columns = [\"Num_Acc\", \"id_vehicule\", \"num_veh\", \"senc\", \"catv\", \"obs\", \"obsm\", \"choc\", \"manv\", \"motor\", \"occutc\"]\n",
    "vehicules_rename = {\"Num_Acc\": \"AccID\", \"id_vehicule\": \"vehicleID\", \"num_veh\": \"num_veh\", \"senc\": \"traffic_direction\", \n",
    "                    \"catv\": \"vehicle_category\", \"obs\": \"fixed_obstacle\", \"obsm\": \"mobile_obstacle\", \"choc\": \"initial_impact_point\", \n",
    "                    \"manv\": \"manv\", \"motor\": \"motor\", \"occutc\": \"number_occupants_publictransport\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783ede6-1892-4eaf-8768-9e523b5893e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each group of files\n",
    "characteristics = process_files(caracteristiques_files, caracteristiques_columns, caracteristiques_rename)\n",
    "locations = process_files(lieux_files, lieux_columns, lieux_rename)\n",
    "users = process_files(usagers_files, usagers_columns, usagers_rename, drop_column=\"id_usager\")\n",
    "vehicles = process_files(vehicules_files, vehicules_columns, vehicules_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fa0fb-cb43-46cf-97f2-d021d0a7609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 to NaN\n",
    "users['reason_travel'] = users['reason_travel'].replace(' -1', '0') # '-1 - Not specified' to '0 - Unknown'\n",
    "characteristics.replace(' -1', np.nan, inplace=True)\n",
    "locations.replace(' -1', np.nan, inplace=True)\n",
    "users.replace(' -1', np.nan, inplace=True)\n",
    "vehicles.replace(' -1', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a46ff-c2e2-468c-be7d-371c1e1b1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'day', 'month', and 'year' fields to integer in the 'characteristics' dataframe\n",
    "characteristics['day'] = pd.to_numeric(characteristics['day'], errors='coerce').astype(pd.Int64Dtype())\n",
    "characteristics['month'] = pd.to_numeric(characteristics['month'], errors='coerce').astype(pd.Int64Dtype())\n",
    "characteristics['year'] = pd.to_numeric(characteristics['year'], errors='coerce').astype(pd.Int64Dtype())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b348fe4-93cc-431f-9a49-afbb51eed4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace invalid literals with NaN and convert specified columns in 'locations' dataframe\n",
    "locations['total_number_lanes'] = pd.to_numeric(locations['total_number_lanes'].replace('#ERREUR', np.nan), errors='coerce').astype(pd.Int64Dtype())\n",
    "locations['maximum_speed'] = pd.to_numeric(locations['maximum_speed'], errors='coerce').astype(pd.Int64Dtype())\n",
    "locations['upstream_terminal_number'] = pd.to_numeric(locations['upstream_terminal_number'], errors='coerce')\n",
    "locations['distance_upstream_terminal'] = pd.to_numeric(locations['distance_upstream_terminal'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34564-a996-448e-9901-bb0e1f51bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace invalid literals with NaN and convert specified columns in 'users' dataframe\n",
    "users['birth_year'] = pd.to_numeric(users['birth_year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839d353-80c3-4ee5-bfad-4ed49b7f51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified columns to object type\n",
    "characteristics['lat'] = characteristics['lat'].str.replace(',', '.').astype(float)\n",
    "characteristics['long'] = characteristics['long'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b10a7-0a22-49f2-9883-e95e2de9abce",
   "metadata": {},
   "source": [
    "<font size=\"6\">  \n",
    "    Merge Dataframes\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370bf5d-3c1e-4cb5-ba94-7cc0cce60523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames on AccID\n",
    "data = characteristics.merge(locations, on='AccID', how='inner') \\\n",
    "                           .merge(vehicles, on='AccID', how='inner') \\\n",
    "                           .merge(users, on=['AccID', 'vehicleID', 'num_veh'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e8b12-499e-4e02-b085-9be01a7d854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate 'age'\n",
    "data['age'] = data['year'] - data['birth_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c89010-cbd5-4721-b460-53d5e5a83e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057403b-1a92-42a5-8c7c-e6924c6b9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all columns where the proportion of NaN values is >= 0.30\n",
    "data = data.loc[:, data.isna().sum() / len(data) < 0.30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5cf08-a1c8-49a7-9025-cde585ceb662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isna().sum() / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2a4ce-69be-45cc-9073-d9e84563c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace NaNs based on existing distribution\n",
    "def fill_na_with_distribution(df, column):\n",
    "    # Calculate value counts for non-NaN values\n",
    "    value_counts = df[column].value_counts(normalize=True)\n",
    "    \n",
    "    # Create a list of values based on the distribution\n",
    "    values = value_counts.index.tolist()\n",
    "    probabilities = value_counts.values.tolist()\n",
    "    \n",
    "    # Number of NaNs to fill\n",
    "    nans_to_fill = df[column].isna().sum()\n",
    "    \n",
    "    # Randomly choose values based on the distribution\n",
    "    fill_values = np.random.choice(values, size=nans_to_fill, p=probabilities)\n",
    "    \n",
    "    # Fill NaNs with these values\n",
    "    df.loc[df[column].isna(), column] = fill_values\n",
    "\n",
    "# Apply the function to each column with NaN values\n",
    "for column in data.columns:\n",
    "    if data[column].isna().sum() > 0:\n",
    "        fill_na_with_distribution(data, column)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84287006-a0d4-4fc1-b9da-62278197bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR test\n",
    "IQR_maximum_speed = data[\"maximum_speed\"].quantile(0.75)-data[\"maximum_speed\"].quantile(0.25)\n",
    "# Lower bound\n",
    "I1_maximum_speed = data[\"maximum_speed\"].quantile(0.25) - 1.5 * IQR_maximum_speed\n",
    "\n",
    "# Upper bound\n",
    "I2_maximum_speed = data[\"maximum_speed\"].quantile(0.75) + 1.5 * IQR_maximum_speed\n",
    "print()\n",
    "print(\"IQR :\", IQR_maximum_speed, end=\"\\n\\n\")\n",
    "print(\"Range :[\", I1_maximum_speed, \";\", I2_maximum_speed, \"]\")\n",
    "data.loc[(data['maximum_speed'] < 5) | (data['maximum_speed'] >125), 'maximum_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8765a6-b62d-4b5c-b0f1-1c81e4a34b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR test\n",
    "IQR_age = data[\"age\"].quantile(0.75)-data[\"age\"].quantile(0.25)\n",
    "# Lower bound\n",
    "I1_age = data[\"age\"].quantile(0.25) - 1.5 * IQR_age\n",
    "\n",
    "# Upper bound\n",
    "I2_age = data[\"age\"].quantile(0.75) + 1.5 * IQR_age\n",
    "print()\n",
    "print(\"IQR :\", IQR_age, end=\"\\n\\n\")\n",
    "print(\"Range :[\", I1_age, \";\", I2_age, \"]\")\n",
    "data.loc[(data['age'] < 0) | (data['age'] >97), 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb511a4-04de-43e9-9671-c30ed33fb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'dep_code' column is numeric\n",
    "data[\"dep_code\"] = pd.to_numeric(data[\"dep_code\"], errors='coerce')\n",
    "\n",
    "# Drop any rows where 'dep_code' could not be converted to a numeric value\n",
    "data = data.dropna(subset=[\"dep_code\"])\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR_dep_code = data[\"dep_code\"].quantile(0.75) - data[\"dep_code\"].quantile(0.25)\n",
    "\n",
    "# Lower bound\n",
    "I1_dep_code = data[\"dep_code\"].quantile(0.25) - 1.5 * IQR_dep_code\n",
    "\n",
    "# Upper bound\n",
    "I2_dep_code = data[\"dep_code\"].quantile(0.75) + 1.5 * IQR_dep_code\n",
    "\n",
    "# Identify outliers\n",
    "outliers = data[(data[\"dep_code\"] < I1_dep_code) | (data[\"dep_code\"] > I2_dep_code)][\"dep_code\"].unique()\n",
    "\n",
    "# Print the IQR and bounds\n",
    "print(\"IQR:\", IQR_dep_code, end=\"\\n\\n\")\n",
    "print(\"Range: [\", I1_dep_code, \";\", I2_dep_code, \"]\")\n",
    "\n",
    "# Print unique outlier values\n",
    "print(\"\\nUnique outlier values:\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d51036-14d7-4d87-bfcb-0be7997f010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "data = data[~((data['maximum_speed'] < 5) | (data['maximum_speed'] > 125))]\n",
    "data = data[~((data['age'] < 0) | (data['age'] > 93))]\n",
    "data = data[~data['dep_code'].isin([988,976,974,972,973,987,986,971,977,978,975])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19def508-2d52-405c-9f19-bb0efab9d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the specified columns\n",
    "columns_to_exclude = ['dep_code', 'com_code', 'location', 'int', 'address', 'route_number_index1', 'route_number']\n",
    "data = data.drop(columns=columns_to_exclude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebcb72-521f-4173-b241-d027ec0c910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = data['time'].apply(lambda x: (int(x.split(':')[0]) * 3600000) +\n",
    "                                       (int(x.split(':')[1]) * 60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8ed58-2424-422a-8d41-6a99440e8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to convert each column individually to identify which ones cause issues\n",
    "problematic_columns = []\n",
    "\n",
    "columns_to_convert = {\n",
    "    'day': 'Int64',\n",
    "    'month': 'Int64',\n",
    "    'year': 'Int64',\n",
    "    'time': 'Int64',\n",
    "    'lum': 'Int64',\n",
    "    'atm_condition': 'Int64',\n",
    "    'collision_type': 'Int64',\n",
    "    'lat': 'float64',\n",
    "    'long': 'float64',\n",
    "    'route_category': 'Int64',\n",
    "    'traffic_regime': 'Int64',\n",
    "    'total_number_lanes': 'Int64',\n",
    "    'reserved_lane_code': 'Int64',\n",
    "    'longitudinal_profile': 'Int64',\n",
    "    'upstream_terminal_number': 'Int64',\n",
    "    'distance_upstream_terminal': 'Int64',\n",
    "    'plan': 'Int64',\n",
    "    'surface_condition': 'Int64',\n",
    "    'infra': 'Int64',\n",
    "    'accident_situation': 'Int64',\n",
    "    'maximum_speed': 'Int64',\n",
    "    'traffic_direction': 'Int64',\n",
    "    'vehicle_category': 'Int64',\n",
    "    'fixed_obstacle': 'Int64',\n",
    "    'mobile_obstacle': 'Int64',\n",
    "    'initial_impact_point': 'Int64',\n",
    "    'manv': 'Int64',\n",
    "    'motor': 'Int64',\n",
    "    'seat': 'Int64',\n",
    "    'user_category': 'Int64',\n",
    "    'gravity': 'Int64',\n",
    "    'gender': 'Int64',\n",
    "    'birth_year': 'Int64',\n",
    "    'reason_travel': 'Int64',\n",
    "    'safety_equipment1': 'Int64',\n",
    "    'age': 'Int64'\n",
    "}\n",
    "\n",
    "for column, dtype in columns_to_convert.items():\n",
    "    try:\n",
    "        data[column].astype(dtype)\n",
    "    except (ValueError, TypeError):\n",
    "        problematic_columns.append(column)\n",
    "\n",
    "problematic_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a516f17-5b98-430b-986c-6855d0d3a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying categorical columns in the dataset\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category', 'int64']).columns.tolist()\n",
    "\n",
    "# Removing 'gravity' from the list as it will be the dependent variable\n",
    "categorical_columns.remove('gravity')\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "chi_square_results_all = {}\n",
    "\n",
    "# Perform Chi-square test between 'gravity' and each categorical variable\n",
    "for column in categorical_columns:\n",
    "    contingency_table = pd.crosstab(data['gravity'], data[column])\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    chi_square_results_all[column] = {\n",
    "        'Chi-square statistic': chi2,\n",
    "        'p-value': p,\n",
    "        'Degrees of freedom': dof,\n",
    "        'Expected frequencies': expected\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "chi_square_results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac5eab-834b-45e8-9162-cbbc0438a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Chi-square statistics for each categorical column\n",
    "chi_square_results_all = {}\n",
    "for column in categorical_columns:\n",
    "    contingency_table = pd.crosstab(data['gravity'], data[column])\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    chi_square_results_all[column] = {\n",
    "        'Chi-square statistic': chi2,\n",
    "        'p-value': p,\n",
    "        'Degrees of freedom': dof,\n",
    "        'Expected frequencies': expected\n",
    "    }\n",
    "\n",
    "# Extracting Chi-square statistics and p-values for visualization\n",
    "variables = list(chi_square_results_all.keys())\n",
    "\n",
    "# Exclude specific fields\n",
    "exclude_fields = {'AccID', 'vehicleID', 'num_veh'}\n",
    "filtered_variables = [var for var in variables if var not in exclude_fields]\n",
    "\n",
    "# Extract the corresponding Chi-square statistics and p-values\n",
    "filtered_chi_square_stats = [chi_square_results_all[var]['Chi-square statistic'] for var in filtered_variables]\n",
    "filtered_p_values = [chi_square_results_all[var]['p-value'] for var in filtered_variables]\n",
    "\n",
    "# Create a bar plot for Chi-square statistics\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(filtered_variables, filtered_chi_square_stats, color='skyblue')\n",
    "plt.xlabel('Chi-square Statistic')\n",
    "plt.title('Chi-square Statistics for Variables with Gravity')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()\n",
    "\n",
    "# Create a bar plot for p-values (log scale)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(filtered_variables, filtered_p_values, color='salmon')\n",
    "plt.xlabel('p-value (log scale)')\n",
    "plt.title('p-values for Chi-square Tests (log scale) with Gravity')\n",
    "plt.yscale('log') \n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd2f1f-675d-4d6a-951e-13b442f07834",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dae9a-c80e-4664-9c16-c72405a43c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a402966-2ed2-4099-b971-4c4918b6671c",
   "metadata": {},
   "source": [
    "<font size=\"6\">  \n",
    "    Export Dataframes\n",
    "</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1fe97-f5de-4524-a05e-c4d5033b2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddc0f2-7617-4f00-9031-8115b81f1bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
