{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c107cfc-1949-40b0-bf00-78bc975414f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 447670 entries, 0 to 447669\n",
      "Data columns (total 39 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   AccID                       447670 non-null  object \n",
      " 1   day                         447670 non-null  object \n",
      " 2   month                       447670 non-null  object \n",
      " 3   year                        447670 non-null  object \n",
      " 4   time                        447670 non-null  object \n",
      " 5   lum                         447670 non-null  object \n",
      " 6   atm_condition               447670 non-null  object \n",
      " 7   collision_type              447670 non-null  object \n",
      " 8   lat                         447670 non-null  float64\n",
      " 9   long                        447670 non-null  float64\n",
      " 10  route_category              447670 non-null  object \n",
      " 11  traffic_regime              447670 non-null  object \n",
      " 12  total_number_lanes          447670 non-null  object \n",
      " 13  reserved_lane_code          447670 non-null  object \n",
      " 14  longitudinal_profile        447670 non-null  object \n",
      " 15  upstream_terminal_number    447670 non-null  float64\n",
      " 16  distance_upstream_terminal  447670 non-null  float64\n",
      " 17  plan                        447670 non-null  object \n",
      " 18  surface_condition           447670 non-null  object \n",
      " 19  infra                       447670 non-null  object \n",
      " 20  accident_situation          447670 non-null  object \n",
      " 21  maximum_speed               447670 non-null  object \n",
      " 22  vehicleID                   447670 non-null  object \n",
      " 23  num_veh                     447670 non-null  object \n",
      " 24  traffic_direction           447670 non-null  object \n",
      " 25  vehicle_category            447670 non-null  object \n",
      " 26  fixed_obstacle              447670 non-null  object \n",
      " 27  mobile_obstacle             447670 non-null  object \n",
      " 28  initial_impact_point        447670 non-null  object \n",
      " 29  manv                        447670 non-null  object \n",
      " 30  motor                       447670 non-null  object \n",
      " 31  seat                        447670 non-null  object \n",
      " 32  user_category               447670 non-null  object \n",
      " 33  gravity                     447670 non-null  object \n",
      " 34  gender                      447670 non-null  object \n",
      " 35  birth_year                  447670 non-null  float64\n",
      " 36  reason_travel               447670 non-null  object \n",
      " 37  safety_equipment1           447670 non-null  object \n",
      " 38  age                         447670 non-null  float64\n",
      "dtypes: float64(6), object(33)\n",
      "memory usage: 133.2+ MB\n",
      "Shape of X_train: (358136, 211)\n",
      "Shape of X_test: (89534, 211)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppress specific future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Import the clean data\n",
    "data = pd.read_pickle('source\\data.pkl')\n",
    "\n",
    "data.info()\n",
    "\n",
    "# Copy of the original dataset for feature engineering and preprocessing\n",
    "data_processed = data.copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data_processed = data_processed.drop(['AccID', 'birth_year', 'vehicleID', 'num_veh'], axis=1)\n",
    "\n",
    "# Convert 'day', 'month', and 'time' to integers\n",
    "data_processed['day'] = data_processed['day'].astype(int)\n",
    "data_processed['month'] = data_processed['month'].astype(int)\n",
    "data_processed['time'] = data_processed['time'].astype(int)\n",
    "\n",
    "# Cyclical encoding for temporal features\n",
    "data_processed['day_sin'] = np.sin(2 * np.pi * data_processed['day'] / 31)  \n",
    "data_processed['day_cos'] = np.cos(2 * np.pi * data_processed['day'] / 31)\n",
    "\n",
    "data_processed['month_sin'] = np.sin(2 * np.pi * data_processed['month'] / 12)\n",
    "data_processed['month_cos'] = np.cos(2 * np.pi * data_processed['month'] / 12)\n",
    "\n",
    "data_processed['time_sin'] = np.sin(2 * np.pi * data_processed['time'] / 86340000) \n",
    "data_processed['time_cos'] = np.cos(2 * np.pi * data_processed['time'] / 86340000)\n",
    "\n",
    "data_processed.drop(columns=['day','month','time'],inplace=True)\n",
    "\n",
    "# Selecting features and target variable\n",
    "features_dummy = ['year', 'lum', 'atm_condition', 'collision_type',\n",
    "       'route_category', 'traffic_regime', 'total_number_lanes',\n",
    "       'reserved_lane_code', 'longitudinal_profile', 'plan',\n",
    "       'surface_condition', 'infra', 'accident_situation',\n",
    "       'traffic_direction', 'vehicle_category', 'fixed_obstacle',\n",
    "       'mobile_obstacle', 'initial_impact_point', 'manv', 'motor', 'seat',\n",
    "       'user_category', 'gender', 'reason_travel',\n",
    "       'safety_equipment1']\n",
    "\n",
    "# These features will be standardized\n",
    "features_scaler = ['lat', 'long', 'upstream_terminal_number', 'distance_upstream_terminal', 'maximum_speed', 'age']\n",
    "\n",
    "# These features are between -1 and 1 and do not need any standardazations. \n",
    "features_temporal = ['day_sin', 'day_cos', 'month_sin', 'month_cos', 'time_sin', 'time_cos']\n",
    "target = 'gravity'\n",
    "\n",
    "X = data_processed.drop(columns=[target])\n",
    "y = data_processed[target]\n",
    "y = y.astype(int)\n",
    "\n",
    "X = pd.get_dummies(X, columns=features_dummy, drop_first=True)\n",
    "\n",
    "# stratify will split the dataset according to the distribution of the classes to compensate for imbalanced datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardization: Fit only on the training data, then apply to both train and test\n",
    "scaler = StandardScaler()\n",
    "X_train[features_scaler] = scaler.fit_transform(X_train[features_scaler])\n",
    "X_test[features_scaler] = scaler.transform(X_test[features_scaler])\n",
    "\n",
    "# Check the dimensions\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf330c-4e55-4eb1-914f-947679236b1c",
   "metadata": {},
   "source": [
    "Apply ML v1 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0269f99a-7b83-4b11-8150-9f827c40aa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680166193848147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78     37537\n",
      "           1       0.44      0.08      0.14      2256\n",
      "           2       0.52      0.44      0.48     13565\n",
      "           3       0.67      0.66      0.66     36176\n",
      "\n",
      "    accuracy                           0.68     89534\n",
      "   macro avg       0.59      0.50      0.51     89534\n",
      "weighted avg       0.67      0.68      0.67     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize XGBoost classifier with default parameters\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Adjust the target variable `y` to start from 0\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "# Train the XGBoost model again with adjusted labels\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_adjusted = accuracy_score(y_test, y_pred)\n",
    "classification_rep_adjusted = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy_adjusted)\n",
    "print(classification_rep_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a314942-9fd7-44db-a2cb-1ec7734a92e2",
   "metadata": {},
   "source": [
    "Apply ML v2 -------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e0418-3db0-4849-a666-c7edd35244cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid,\n",
    "                                   n_iter=10, scoring='f1', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from the tuning process\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Use the best estimator to predict\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report for the tuned model\n",
    "tuned_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "tuned_classification_report = classification_report(y_test, y_pred_tuned)\n",
    "\n",
    "print(best_params)\n",
    "print(tuned_accuracy)\n",
    "print(tuned_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd2bb7-3a7c-4f9a-b65e-7cf4faaa8ea7",
   "metadata": {},
   "source": [
    "Apply ML v3--------> Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5e5db2-c46a-4023-ba0c-8eb34763c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "0.6678133446511939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77     37537\n",
      "           1       0.47      0.03      0.05      2256\n",
      "           2       0.52      0.38      0.44     13565\n",
      "           3       0.65      0.64      0.65     36176\n",
      "\n",
      "    accuracy                           0.67     89534\n",
      "   macro avg       0.59      0.47      0.48     89534\n",
      "weighted avg       0.65      0.67      0.65     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'min_child_weight': [5],\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid,\n",
    "                                   n_iter=10, scoring='f1', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from the tuning process\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Use the best estimator to predict\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report for the tuned model\n",
    "tuned_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "tuned_classification_report = classification_report(y_test, y_pred_tuned)\n",
    "\n",
    "print(best_params)\n",
    "print(tuned_accuracy)\n",
    "print(tuned_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1c7c2-cb8e-4f88-aa81-6ae8e5734b41",
   "metadata": {},
   "source": [
    "Apply ML v4--------> SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d6dbab-82a1-4598-b152-491b2ff6e66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:37:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.74      0.81      0.77     37537\\n           1       0.30      0.16      0.21      2256\\n           2       0.48      0.47      0.47     13565\\n           3       0.67      0.63      0.65     36176\\n\\n    accuracy                           0.67     89534\\n   macro avg       0.55      0.52      0.52     89534\\nweighted avg       0.66      0.67      0.66     89534\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# SMOTE for oversampling the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Initialize the XGBoost classifier with class weights\n",
    "xgb_model_balanced = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, scale_pos_weight=class_weight_dict)\n",
    "\n",
    "# Train the model on the resampled data\n",
    "xgb_model_balanced.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_balanced = xgb_model_balanced.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report_balanced = classification_report(y_test, y_pred_balanced)\n",
    "\n",
    "report_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83461230-bac6-4b01-ac9b-bf5473a48ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77     37537\n",
      "           1       0.30      0.16      0.21      2256\n",
      "           2       0.48      0.47      0.47     13565\n",
      "           3       0.67      0.63      0.65     36176\n",
      "\n",
      "    accuracy                           0.67     89534\n",
      "   macro avg       0.55      0.52      0.52     89534\n",
      "weighted avg       0.66      0.67      0.66     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6ab9e-2754-4164-8274-1898a54803c4",
   "metadata": {},
   "source": [
    "Apply ML v5--------> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79cc0884-3abc-482d-9f11-0ddfa94d2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to train and evaluate the model\n",
    "def train_and_evaluate(X_train_resampled, y_train_resampled, X_test, y_test, class_weight=None):\n",
    "    # Initialize the XGBoost classifier\n",
    "    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    \n",
    "    # Apply class weights if specified\n",
    "    if class_weight:\n",
    "        xgb_model.set_params(scale_pos_weight=class_weight)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Generate and return the classification report\n",
    "    return classification_report(y_test, y_pred)\n",
    "\n",
    "# Original split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardization: Fit only on training data\n",
    "scaler = StandardScaler()\n",
    "X_train[features_scaler] = scaler.fit_transform(X_train[features_scaler])\n",
    "X_test[features_scaler] = scaler.transform(X_test[features_scaler])\n",
    "\n",
    "# Adjust the target variable `y` to start from 0\n",
    "y_train_adjusted = y_train - 1\n",
    "y_test_adjusted = y_test - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5bc49c-6045-41ec-a60f-e647ea152fdf",
   "metadata": {},
   "source": [
    "--------> RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1972fb34-e094-4793-aef6-15d409c08f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomUnderSampler Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76     37537\n",
      "           1       0.14      0.63      0.23      2256\n",
      "           2       0.38      0.44      0.41     13565\n",
      "           3       0.71      0.48      0.57     36176\n",
      "\n",
      "    accuracy                           0.60     89534\n",
      "   macro avg       0.49      0.58      0.49     89534\n",
      "weighted avg       0.66      0.60      0.62     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res_rus, y_train_res_rus = rus.fit_resample(X_train, y_train_adjusted)\n",
    "report_rus = train_and_evaluate(X_train_res_rus, y_train_res_rus, X_test, y_test_adjusted)\n",
    "print(\"RandomUnderSampler Report:\\n\", report_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e0b76-79a6-4bb3-b1e3-021c22cdd8d4",
   "metadata": {},
   "source": [
    "--------> RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c25e9c7-0ab1-481c-b43a-28a6bb597539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomOverSampler Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77     37537\n",
      "           1       0.16      0.56      0.25      2256\n",
      "           2       0.41      0.51      0.45     13565\n",
      "           3       0.72      0.51      0.60     36176\n",
      "\n",
      "    accuracy                           0.63     89534\n",
      "   macro avg       0.51      0.59      0.52     89534\n",
      "weighted avg       0.67      0.63      0.64     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res_ros, y_train_res_ros = ros.fit_resample(X_train, y_train_adjusted)\n",
    "report_ros = train_and_evaluate(X_train_res_ros, y_train_res_ros, X_test, y_test_adjusted)\n",
    "print(\"RandomOverSampler Report:\\n\", report_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90821482-a493-4bef-878a-3e13ec94184b",
   "metadata": {},
   "source": [
    "--------> Class Weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc6d06cf-d8c8-4bd6-9b4d-e8aa8a8ac7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:11:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "Class Weight Argument Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78     37537\n",
      "           1       0.44      0.08      0.14      2256\n",
      "           2       0.52      0.44      0.48     13565\n",
      "           3       0.67      0.66      0.66     36176\n",
      "\n",
      "    accuracy                           0.68     89534\n",
      "   macro avg       0.59      0.50      0.51     89534\n",
      "weighted avg       0.67      0.68      0.67     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_adjusted), y=y_train_adjusted)\n",
    "class_weight_dict = dict(zip(np.unique(y_train_adjusted), class_weights))\n",
    "report_class_weight = train_and_evaluate(X_train, y_train_adjusted, X_test, y_test_adjusted, class_weight=class_weight_dict)\n",
    "print(\"Class Weight Argument Report:\\n\", report_class_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e28e4-f0f3-443c-bbdd-2124cf7dc6d8",
   "metadata": {},
   "source": [
    "##### Apply ML v7--------> SMOTE and Undersampling Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f3df2f-b2d8-476b-81d4-c49826798924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE + Undersampling Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77     37537\n",
      "           1       0.30      0.16      0.21      2256\n",
      "           2       0.48      0.47      0.47     13565\n",
      "           3       0.67      0.63      0.65     36176\n",
      "\n",
      "    accuracy                           0.67     89534\n",
      "   macro avg       0.55      0.52      0.52     89534\n",
      "weighted avg       0.66      0.67      0.66     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the SMOTE + RandomUnderSampler pipeline\n",
    "sampling_pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),                # SMOTE to oversample minority classes\n",
    "    ('undersample', RandomUnderSampler(random_state=42))  # Undersample majority classes\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the training data\n",
    "X_train_resampled, y_train_resampled = sampling_pipeline.fit_resample(X_train, y_train_adjusted)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model_combined = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Train the model on the resampled data\n",
    "xgb_model_combined.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_combined = xgb_model_combined.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report_combined = classification_report(y_test_adjusted, y_pred_combined)\n",
    "print(\"SMOTE + Undersampling Report:\\n\", report_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f47f2-23d2-42a2-8cc1-8c9663e895fd",
   "metadata": {},
   "source": [
    "SMOTE + Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc33113-9b82-4381-bbf1-685f5fe0f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE + Tomek Links Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.77     37537\n",
      "           1       0.29      0.17      0.22      2256\n",
      "           2       0.47      0.51      0.49     13565\n",
      "           3       0.68      0.60      0.64     36176\n",
      "\n",
      "    accuracy                           0.67     89534\n",
      "   macro avg       0.54      0.52      0.53     89534\n",
      "weighted avg       0.66      0.67      0.66     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled_tomek, y_train_resampled_tomek = smote_tomek.fit_resample(X_train, y_train_adjusted)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model_tomek = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_tomek.fit(X_train_resampled_tomek, y_train_resampled_tomek)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tomek = xgb_model_tomek.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report_tomek = classification_report(y_test_adjusted, y_pred_tomek)\n",
    "print(\"SMOTE + Tomek Links Report:\\n\", report_tomek)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474629e3-e1fd-4633-aff0-5d5c903e72c1",
   "metadata": {},
   "source": [
    "SMOTE + ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da2d7bf0-1c3d-43cf-82a6-89a997354bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE + ENN Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75     37537\n",
      "           1       0.20      0.31      0.24      2256\n",
      "           2       0.32      0.77      0.45     13565\n",
      "           3       0.74      0.34      0.47     36176\n",
      "\n",
      "    accuracy                           0.57     89534\n",
      "   macro avg       0.50      0.54      0.48     89534\n",
      "weighted avg       0.67      0.57      0.58     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SMOTE + ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled_enn, y_train_resampled_enn = smote_enn.fit_resample(X_train, y_train_adjusted)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model_enn = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_enn.fit(X_train_resampled_enn, y_train_resampled_enn)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_enn = xgb_model_enn.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report_enn = classification_report(y_test_adjusted, y_pred_enn)\n",
    "print(\"SMOTE + ENN Report:\\n\", report_enn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfde42-3656-4c89-b664-c76a75790ac5",
   "metadata": {},
   "source": [
    "SMOTE + ENN with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730f16b8-ba17-4593-9c69-69571be720a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sd10725\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:07:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "SMOTE + ENN with Class Weights Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75     37537\n",
      "           1       0.20      0.31      0.24      2256\n",
      "           2       0.32      0.77      0.45     13565\n",
      "           3       0.74      0.34      0.47     36176\n",
      "\n",
      "    accuracy                           0.57     89534\n",
      "   macro avg       0.50      0.54      0.48     89534\n",
      "weighted avg       0.67      0.57      0.58     89534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Apply SMOTE + ENN for resampling\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train_adjusted)\n",
    "\n",
    "# Calculate class weights based on the original y_train distribution\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_adjusted), y=y_train_adjusted)\n",
    "class_weight_dict = dict(zip(np.unique(y_train_adjusted), class_weights))\n",
    "\n",
    "# Initialize XGBoost classifier with class weights\n",
    "xgb_model_combined_weighted = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42,\n",
    "                                            scale_pos_weight=class_weight_dict)\n",
    "\n",
    "# Train the model on the resampled data\n",
    "xgb_model_combined_weighted.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_combined_weighted = xgb_model_combined_weighted.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report_combined_weighted = classification_report(y_test_adjusted, y_pred_combined_weighted)\n",
    "print(\"SMOTE + ENN with Class Weights Report:\\n\", report_combined_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa74d703-e183-4f03-8997-13f09d013cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shap in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (1.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (24.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from numba->shap) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sd10725\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9b6702-7d9f-4dac-9bef-6bdb0b9e6682",
   "metadata": {},
   "source": [
    " LIME explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab38b222-17af-4c81-99bf-e0955113f324",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime_tabular\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lime'"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values,\n",
    "    mode='classification',\n",
    "    training_labels=y_train_adjusted,\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=np.unique(y_train_adjusted).astype(str),\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# Choose an instance to explain (e.g., the first instance in the test set)\n",
    "instance_index = 0\n",
    "instance = X_test.iloc[instance_index].values.reshape(1, -1)\n",
    "\n",
    "# Generate LIME explanation\n",
    "exp = explainer.explain_instance(instance.flatten(), xgb_model_combined_weighted.predict_proba, num_features=10)\n",
    "\n",
    "# Display the explanation\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea028256-1a88-4f32-b6b1-3e373997ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP explaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83398e7d-9e27-4440-a950-2057ad6e7356",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the SHAP explainer (TreeExplainer is optimized for tree-based models like XGBoost)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer(xgb_model_combined_weighted)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize the SHAP explainer (TreeExplainer is optimized for tree-based models like XGBoost)\n",
    "explainer = shap.TreeExplainer(xgb_model_combined_weighted)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary Plot - Shows feature importance across all predictions\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "\n",
    "# Force Plot - Explains a single prediction\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][instance_index], X_test.iloc[instance_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39887e-eef2-450b-9c57-c6e94c4fc094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
